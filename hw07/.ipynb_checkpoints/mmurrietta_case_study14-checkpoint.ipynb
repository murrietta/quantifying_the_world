{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classifying the Higgs Boson Using Neural Networks\n",
    "\n",
    "Michael Murrietta\n",
    "\n",
    "4/19/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#documentation says the last 500000 are used as the test set. the data has 11000000 rows total!\n",
    "data=pd.read_csv(\"~/Downloads/HIGGS.csv\",nrows=1000000,header=None)\n",
    "test_data=pd.read_csv(\"~/Downloads/HIGGS.csv\",nrows=500000,header=None,skiprows=11000000 - 500000)\n",
    "\n",
    "y=np.array(data.loc[:,0])\n",
    "x=np.array(data.loc[:,1:])\n",
    "x_test=test_data.loc[:,1:]\n",
    "y_test=test_data.loc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some functions I used to help maintain sanity as I explored different model configurations. The first one was used only once and just allowed me to specify however many layers I wanted and the learning rate and decay rate for the `SGD` optimizer. As will be mentioned below, this really just allowed for exploration of the learning and decay rates. The second function allows for different optimizers to be used but only allows use of the default parameters for those optimizers (I tried to get the `**kwargs` working but I did not work it out as quickly as I thought I would)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_test_old(layers, opt_args, mtrcs=['accuracy', 'mae'], epochs= 5, verbose=True):\n",
    "\t#layers is a list of lists where each inner list defines a dens layer\n",
    "\t#\tfor layer in layers: layer[0] is # of nodes in layer, layer[1] is\n",
    "\t#\tkernel initializer, layer[2] is activation function\n",
    "\tmodel = Sequential()\n",
    "\tlayer = layers[0]\n",
    "\tmodel.add(Dense(layer[0], input_dim=x.shape[1], kernel_initializer=layer[1], activation=layer[2]))\n",
    "\tfor layer in layers[1:]:\n",
    "\t\tmodel.add(Dense(layer[0], kernel_initializer=layer[1], activation=layer[2]))\n",
    "\tmodel.add(Dense(1, kernel_initializer=layers[0][1], activation='sigmoid')) #uses 1st layer's initializer\n",
    "\n",
    "\t#for now just have opt be default\n",
    "\topt= SGD(lr = opt_args[0], decay = opt_args[1], momentum=0.9, nesterov=True)\n",
    "\tmodel.compile(loss='binary_crossentropy', metrics=mtrcs, optimizer=opt)\n",
    "\n",
    "\tbatch_size=100\n",
    "\tmodel.fit(x, y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\tscore = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\t#compute and print results\n",
    "\ts = score + [roc_auc_score(y_test,model.predict(x_test))]\n",
    "\tif verbose:\n",
    "\t\tscoreStr = [\"{:>20}: {:>.4}\".format(\"Test Loss\",score[0])] + \\\n",
    "\t\t\t[\"{:>20}: {:>.4}\".format(\"Test {}\".format(x), y) for x, y in zip(mtrcs, score[1:])] + \\\n",
    "\t\t\t[\"{:>20}: {:>.4}\".format(\"Test ROCAUC\", s[-1])]\n",
    "\t\tprint(\"\\n\".join(scoreStr))\n",
    "\t#return results\n",
    "\treturn s\n",
    "\n",
    "def model_test(layers, opt, opt_args=None, mtrcs=['accuracy', 'mae'], epochs= 5, verbose=True):\n",
    "\t#layers is a list of lists where each inner list defines a dens layer\n",
    "\t#\tfor layer in layers: layer[0] is # of nodes in layer, layer[1] is\n",
    "\t#\tkernel initializer, layer[2] is activation function\n",
    "\tmodel = Sequential()\n",
    "\tlayer = layers[0]\n",
    "\tmodel.add(Dense(layer[0], input_dim=x.shape[1], kernel_initializer=layer[1], activation=layer[2]))\n",
    "\tfor layer in layers[1:]:\n",
    "\t\tmodel.add(Dense(layer[0], kernel_initializer=layer[1], activation=layer[2]))\n",
    "\tmodel.add(Dense(1, kernel_initializer=layers[0][1], activation='sigmoid')) #uses 1st layer's initializer\n",
    "\n",
    "\t#for now just have opt be default\n",
    "\tmodel.compile(loss='binary_crossentropy', metrics=mtrcs, optimizer=opt)\n",
    "\n",
    "\tbatch_size=100\n",
    "\tmodel.fit(x, y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\tscore = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\t#compute and print results\n",
    "\ts = score + [roc_auc_score(y_test,model.predict(x_test))]\n",
    "\tif verbose:\n",
    "\t\tscoreStr = [\"{:>20}: {:>.4}\".format(\"Test Loss\",score[0])] + \\\n",
    "\t\t\t[\"{:>20}: {:>.4}\".format(\"Test {}\".format(x), y) for x, y in zip(mtrcs, score[1:])] + \\\n",
    "\t\t\t[\"{:>20}: {:>.4}\".format(\"Test ROCAUC\", s[-1])]\n",
    "\t\tprint(\"\\n\".join(scoreStr))\n",
    "\t#return results\n",
    "\treturn s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a cell that will take around 5 hours to compute as it runs 180 different configurations of a 2-hidden layer neural network. This was a lazy attempt to get some insight and in the end I only really learned about the SGD optimizer! Particularly that with these networks I should keep the learning rate at either 0.01 or 0.03 and the decay rate between 0 and 0.00018, all models that did not have these properties were terrible and sometimes worse than a guess where the receiver-operating characteristic area-under-the-curve (ROCAUC) was less than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Dont run unless you want to wait about 5 hours...\n",
    "# import random\n",
    "# import itertools\n",
    "# layer_list = [[[x*10, \"uniform\", random.choice(['relu','tanh','sigmoid'])] for x in np.random.randint(4, 10, 3)]]\n",
    "# lrates = [0.01*(3**x) for x in range(6)]\n",
    "# drates = [10*x*(1e-6) for x in range(20)]\n",
    "# opt_args = itertools.product(lrates, drates)\n",
    "# params = [x for x in itertools.product(layer_list, opt_args)]\n",
    "\n",
    "# sdat = []\n",
    "# for i, param in enumerate(params):\n",
    "# \tprint(\"Trial {:>3} of {:>3}\".format(i, len(params)))\n",
    "# \tsdat.append(model_test_old(param[0], param[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous to the above shotgun approach a more manual exploration was done yielded a few models with ROCAUC around 0.82. Some things learned from this previous work was that using a batch size of 100 is probably the best for this case since a smaller size greatly increases the time needed to train and a larger number greatly reduces the ROCAUC. The best of these became the starting point for the more intentional exploration that follows. The following cells explore the following aspects of a neural network in the following order:\n",
    "+ <b>Optimizers</b>: Explored all optimizers in Keras and found `Adadelta` to be best in this case\n",
    "+ <b>Number of Layers</b>: Used between 2 and 5 hidden layers, found 3 hidden layers to be best\n",
    "+ <b>Activations</b>: Previous exploration used only the `relu` activation on every layer, here the `tanh` activation was tried at various layers. It was found that using the `tanh` activation in the first layer was best.\n",
    "+ <b>Number of Nodes</b>: Explored where a good place for a 50 node layer amongst the 80 node layers would be. The results showed that having the first layer use 50 nodes and the others use 80 nodes was the best of those tried.\n",
    "+ <b>Kernel Initializers</b>: There are nearly a dozen kernel initializers included in Keras and about 5 of them were tried. The results showed that the `Orthogonal` initializer worked best with the model that was in use at this point.\n",
    "+ <b>Number of Nodes 2</b>: Explored the number of nodes again but this time trying different values than just 50 and 80. Of the configurations tried the best was 20, 100, 100, and 140 nodes, respectively.\n",
    "+ <b>Activations 2</b>: Previously only explored `relu` and `tanh`, now included a layer with no activation function which makes the layer just perform a linear transformation on the output of the previous layer. The best result in this section used a linear-transformation-only layer at the input layer. Intuitively this can be perceived as the model allowing the input signals to move through at least one layer before dropping their effect. Also at this point the number of epochs was increased to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "OPTIMIZER: Adagrad\n",
      "Epoch 1/10\n",
      " - 25s - loss: 0.6078 - acc: 0.6653 - mean_absolute_error: 0.4224\n",
      "Epoch 2/10\n",
      " - 22s - loss: 0.5833 - acc: 0.6887 - mean_absolute_error: 0.4008\n",
      "Epoch 3/10\n",
      " - 22s - loss: 0.5757 - acc: 0.6951 - mean_absolute_error: 0.3945\n",
      "Epoch 4/10\n",
      " - 22s - loss: 0.5702 - acc: 0.6999 - mean_absolute_error: 0.3901\n",
      "Epoch 5/10\n",
      " - 22s - loss: 0.5656 - acc: 0.7035 - mean_absolute_error: 0.3862\n",
      "Epoch 6/10\n",
      " - 22s - loss: 0.5619 - acc: 0.7070 - mean_absolute_error: 0.3831\n",
      "Epoch 7/10\n",
      " - 22s - loss: 0.5591 - acc: 0.7093 - mean_absolute_error: 0.3808\n",
      "Epoch 8/10\n",
      " - 22s - loss: 0.5568 - acc: 0.7112 - mean_absolute_error: 0.3788\n",
      "Epoch 9/10\n",
      " - 22s - loss: 0.5549 - acc: 0.7131 - mean_absolute_error: 0.3772\n",
      "Epoch 10/10\n",
      " - 21s - loss: 0.5533 - acc: 0.7142 - mean_absolute_error: 0.3758\n",
      "500000/500000 [==============================] - 9s 18us/step\n",
      "           Test Loss: 0.5518\n",
      "       Test accuracy: 0.7151\n",
      "            Test mae: 0.3727\n",
      "         Test ROCAUC: 0.7894\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "OPTIMIZER: Adam\n",
      "Epoch 1/10\n",
      " - 24s - loss: 0.5955 - acc: 0.6746 - mean_absolute_error: 0.4107\n",
      "Epoch 2/10\n",
      " - 25s - loss: 0.5607 - acc: 0.7075 - mean_absolute_error: 0.3808\n",
      "Epoch 3/10\n",
      " - 26s - loss: 0.5448 - acc: 0.7197 - mean_absolute_error: 0.3678\n",
      "Epoch 4/10\n",
      " - 25s - loss: 0.5340 - acc: 0.7275 - mean_absolute_error: 0.3592\n",
      "Epoch 5/10\n",
      " - 24s - loss: 0.5271 - acc: 0.7319 - mean_absolute_error: 0.3538\n",
      "Epoch 6/10\n",
      " - 16s - loss: 0.5221 - acc: 0.7358 - mean_absolute_error: 0.3499\n",
      "Epoch 7/10\n",
      " - 15s - loss: 0.5189 - acc: 0.7379 - mean_absolute_error: 0.3473\n",
      "Epoch 8/10\n",
      " - 21s - loss: 0.5160 - acc: 0.7400 - mean_absolute_error: 0.3450\n",
      "Epoch 9/10\n",
      " - 25s - loss: 0.5135 - acc: 0.7411 - mean_absolute_error: 0.3431\n",
      "Epoch 10/10\n",
      " - 26s - loss: 0.5116 - acc: 0.7426 - mean_absolute_error: 0.3417\n",
      "500000/500000 [==============================] - 9s 18us/step\n",
      "           Test Loss: 0.5104\n",
      "       Test accuracy: 0.7438\n",
      "            Test mae: 0.342\n",
      "         Test ROCAUC: 0.8257\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "OPTIMIZER: Adamax\n",
      "Epoch 1/10\n",
      " - 27s - loss: 0.5987 - acc: 0.6720 - mean_absolute_error: 0.4136\n",
      "Epoch 2/10\n",
      " - 26s - loss: 0.5607 - acc: 0.7069 - mean_absolute_error: 0.3810\n",
      "Epoch 3/10\n",
      " - 26s - loss: 0.5453 - acc: 0.7193 - mean_absolute_error: 0.3683\n",
      "Epoch 4/10\n",
      " - 25s - loss: 0.5340 - acc: 0.7271 - mean_absolute_error: 0.3594\n",
      "Epoch 5/10\n",
      " - 26s - loss: 0.5264 - acc: 0.7328 - mean_absolute_error: 0.3534\n",
      "Epoch 6/10\n",
      " - 24s - loss: 0.5205 - acc: 0.7364 - mean_absolute_error: 0.3488\n",
      "Epoch 7/10\n",
      " - 25s - loss: 0.5165 - acc: 0.7390 - mean_absolute_error: 0.3457\n",
      "Epoch 8/10\n",
      " - 24s - loss: 0.5128 - acc: 0.7416 - mean_absolute_error: 0.3428\n",
      "Epoch 9/10\n",
      " - 25s - loss: 0.5101 - acc: 0.7435 - mean_absolute_error: 0.3406\n",
      "Epoch 10/10\n",
      " - 24s - loss: 0.5079 - acc: 0.7447 - mean_absolute_error: 0.3389\n",
      "500000/500000 [==============================] - 9s 18us/step\n",
      "           Test Loss: 0.5086\n",
      "       Test accuracy: 0.7449\n",
      "            Test mae: 0.3408\n",
      "         Test ROCAUC: 0.8266\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "OPTIMIZER: Nadam\n",
      "Epoch 1/10\n",
      " - 29s - loss: 0.5903 - acc: 0.6803 - mean_absolute_error: 0.4058\n",
      "Epoch 2/10\n",
      " - 29s - loss: 0.5573 - acc: 0.7102 - mean_absolute_error: 0.3780\n",
      "Epoch 3/10\n",
      " - 28s - loss: 0.5450 - acc: 0.7198 - mean_absolute_error: 0.3680\n",
      "Epoch 4/10\n",
      " - 27s - loss: 0.5363 - acc: 0.7260 - mean_absolute_error: 0.3610\n",
      "Epoch 5/10\n",
      " - 26s - loss: 0.5290 - acc: 0.7309 - mean_absolute_error: 0.3551\n",
      "Epoch 6/10\n",
      " - 18s - loss: 0.5228 - acc: 0.7352 - mean_absolute_error: 0.3503\n",
      "Epoch 7/10\n",
      " - 15s - loss: 0.5188 - acc: 0.7381 - mean_absolute_error: 0.3472\n",
      "Epoch 8/10\n",
      " - 15s - loss: 0.5157 - acc: 0.7395 - mean_absolute_error: 0.3447\n",
      "Epoch 9/10\n",
      " - 16s - loss: 0.5140 - acc: 0.7411 - mean_absolute_error: 0.3433\n",
      "Epoch 10/10\n",
      " - 15s - loss: 0.5124 - acc: 0.7422 - mean_absolute_error: 0.3421\n",
      "500000/500000 [==============================] - 5s 11us/step\n",
      "           Test Loss: 0.5104\n",
      "       Test accuracy: 0.7428\n",
      "            Test mae: 0.3433\n",
      "         Test ROCAUC: 0.8248\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "OPTIMIZER: RMSprop\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.5994 - acc: 0.6718 - mean_absolute_error: 0.4133\n",
      "Epoch 2/10\n",
      " - 14s - loss: 0.5613 - acc: 0.7080 - mean_absolute_error: 0.3804\n",
      "Epoch 3/10\n",
      " - 15s - loss: 0.5444 - acc: 0.7206 - mean_absolute_error: 0.3665\n",
      "Epoch 4/10\n",
      " - 14s - loss: 0.5340 - acc: 0.7280 - mean_absolute_error: 0.3581\n",
      "Epoch 5/10\n",
      " - 15s - loss: 0.5275 - acc: 0.7330 - mean_absolute_error: 0.3528\n",
      "Epoch 6/10\n",
      " - 15s - loss: 0.5244 - acc: 0.7357 - mean_absolute_error: 0.3501\n",
      "Epoch 7/10\n",
      " - 15s - loss: 0.5230 - acc: 0.7364 - mean_absolute_error: 0.3487\n",
      "Epoch 8/10\n",
      " - 15s - loss: 0.5226 - acc: 0.7371 - mean_absolute_error: 0.3480\n",
      "Epoch 9/10\n",
      " - 15s - loss: 0.5232 - acc: 0.7371 - mean_absolute_error: 0.3481\n",
      "Epoch 10/10\n",
      " - 15s - loss: 0.5240 - acc: 0.7365 - mean_absolute_error: 0.3486\n",
      "500000/500000 [==============================] - 5s 11us/step\n",
      "           Test Loss: 0.518\n",
      "       Test accuracy: 0.7403\n",
      "            Test mae: 0.3464\n",
      "         Test ROCAUC: 0.8203\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "OPTIMIZER: Adadelta\n",
      "Epoch 1/10\n",
      " - 24s - loss: 0.5955 - acc: 0.6738 - mean_absolute_error: 0.4104\n",
      "Epoch 2/10\n",
      " - 27s - loss: 0.5614 - acc: 0.7070 - mean_absolute_error: 0.3811\n",
      "Epoch 3/10\n",
      " - 29s - loss: 0.5469 - acc: 0.7184 - mean_absolute_error: 0.3693\n",
      "Epoch 4/10\n",
      " - 25s - loss: 0.5351 - acc: 0.7270 - mean_absolute_error: 0.3598\n",
      "Epoch 5/10\n",
      " - 26s - loss: 0.5255 - acc: 0.7339 - mean_absolute_error: 0.3521\n",
      "Epoch 6/10\n",
      " - 27s - loss: 0.5186 - acc: 0.7384 - mean_absolute_error: 0.3467\n",
      "Epoch 7/10\n",
      " - 27s - loss: 0.5142 - acc: 0.7417 - mean_absolute_error: 0.3431\n",
      "Epoch 8/10\n",
      " - 27s - loss: 0.5110 - acc: 0.7436 - mean_absolute_error: 0.3405\n",
      "Epoch 9/10\n",
      " - 27s - loss: 0.5085 - acc: 0.7452 - mean_absolute_error: 0.3386\n",
      "Epoch 10/10\n",
      " - 28s - loss: 0.5061 - acc: 0.7469 - mean_absolute_error: 0.3367\n",
      "500000/500000 [==============================] - 10s 20us/step\n",
      "           Test Loss: 0.5031\n",
      "       Test accuracy: 0.7492\n",
      "            Test mae: 0.333\n",
      "         Test ROCAUC: 0.8309\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------\n",
    "#lets try some of the better models from manual exploration\n",
    "#this layer setup comes from one that had a rocauc of 0.8276\n",
    "#try a few different optimizers\n",
    "opts = [Adagrad(), Adam(), Adamax(), Nadam(), RMSprop(), Adadelta()]\n",
    "names = \"Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\".split(', ')\n",
    "layer_list = [[[x, \"uniform\", \"relu\"] for x in [50, 80, 80]]]\n",
    "for i, opt in enumerate(opts):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"OPTIMIZER: {}\".format(names[i]))\n",
    "\tnp.random.seed(128)\n",
    "\tmodel_test(layer_list[0], opt, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exploring number of layers\n",
    "layer_list = [[[x*10, \"uniform\", \"relu\"] for x in [8, 8, 8]],\n",
    "\t[[x*10, \"uniform\", \"relu\"] for x in [8, 8, 8, 8]],\n",
    "\t[[x*10, \"uniform\", \"relu\"] for x in [8, 8, 8, 8, 8]],\n",
    "\t[[x*10, \"uniform\", \"relu\"] for x in [8, 8, 8, 8, 8, 8]]]\n",
    "\n",
    "sdat = []\n",
    "opt = Adadelta()\n",
    "for i, layer in enumerate(layer_list):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"LAYER CONFIG: {}\".format(i))\n",
    "\tnp.random.seed(128)\n",
    "\tsdat.append(model_test(layer, opt, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exploring the use of something other than `relu`, namely, `tanh`\n",
    "layer_list = [[[80, \"uniform\", x] for x in [\"tanh\", \"relu\", \"relu\", \"relu\"]],\n",
    "\t[[80, \"uniform\", x] for x in [\"relu\", \"tanh\", \"relu\", \"relu\"]],\n",
    "\t[[80, \"uniform\", x] for x in [\"relu\", \"relu\", \"tanh\", \"relu\"]],\n",
    "\t[[80, \"uniform\", x] for x in [\"relu\", \"relu\", \"relu\", \"tanh\"]],\n",
    "\t[[80, \"uniform\", x] for x in [\"tanh\", \"relu\", \"relu\", \"tanh\"]]]\n",
    "\n",
    "sdat = []\n",
    "opt = Adadelta()\n",
    "for i, layer in enumerate(layer_list):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"LAYER CONFIG: {}\".format(i))\n",
    "\tnp.random.seed(128)\n",
    "\tsdat.append(model_test(layer, opt, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing number of nodes in each layer.\n",
    "layer_list = [[[i, \"uniform\", x] for i, x in zip([50, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"uniform\", x] for i, x in zip([80, 50, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"uniform\", x] for i, x in zip([80, 80, 50, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"uniform\", x] for i, x in zip([80, 80, 80, 50], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"uniform\", x] for i, x in zip([50, 80, 80, 50], [\"tanh\", \"relu\", \"relu\", \"relu\"])]]\n",
    "\n",
    "sdat = []\n",
    "opt = Adadelta()\n",
    "for i, layer in enumerate(layer_list):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"LAYER CONFIG: {}\".format(i))\n",
    "\tnp.random.seed(128)\n",
    "\tsdat.append(model_test(layer, opt, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exploring some of the kernel initializers included in keras\n",
    "layer_list = [[[i, \"VarianceScaling\", x] for i, x in zip([50, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8296\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([50, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8326\n",
    "\t[[i, \"lecun_uniform\", x] for i, x in zip([50, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8305\n",
    "\t[[i, \"lecun_normal\", x] for i, x in zip([50, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8289\n",
    "\t[[i, \"he_normal\", x] for i, x in zip([50, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])]] #0.8321\n",
    "\n",
    "sdat = []\n",
    "opt = Adadelta()\n",
    "for i, layer in enumerate(layer_list):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"LAYER CONFIG: {}\".format(i))\n",
    "\tnp.random.seed(128)\n",
    "\tsdat.append(model_test(layer, opt, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of nodes revisited. thinking that the best number of nodes used in each layer depends on the layer\n",
    "#before it and also the layer after it... essentially depends on the number of input features and the \n",
    "#number of classes. Here is just a large list of different node configurations for the 3 hidden layer model\n",
    "#that has been used\n",
    "layer_list = [[[i, \"orthogonal\", x] for i, x in zip([40, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([30, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([10, 80, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 50, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8291\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 80, 50, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8278\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 80, 80, 50], [\"tanh\", \"relu\", \"relu\", \"relu\"])],\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100, 80, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8314\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 80, 100, 80], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8285\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 80, 80, 100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8309\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100, 80, 100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8309\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8334\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,120,100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8327\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,120,120], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8315\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,120,140], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8326\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,20,100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.829\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 20,20,20], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8161\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 20,20,100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8185\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 20,100,100], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8258\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,20,20], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8298\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 20,100,20], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.822\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8334\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,120], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8314\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,160], [\"tanh\", \"relu\", \"relu\", \"relu\"])], #0.8299\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,180], [\"tanh\", \"relu\", \"relu\", \"relu\"])] #0.8329\n",
    "\t]\n",
    "\n",
    "sdat = []\n",
    "opt = Adadelta()\n",
    "for i, layer in enumerate(layer_list):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"LAYER CONFIG: {}\".format(i))\n",
    "\tnp.random.seed(128)\n",
    "\tsdat.append(model_test(layer, opt, epochs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 0\n",
      "Epoch 1/15\n",
      " - 25s - loss: 0.5874 - acc: 0.6835 - mean_absolute_error: 0.4031\n",
      "Epoch 2/15\n",
      " - 22s - loss: 0.5501 - acc: 0.7163 - mean_absolute_error: 0.3714\n",
      "Epoch 3/15\n",
      " - 21s - loss: 0.5346 - acc: 0.7273 - mean_absolute_error: 0.3590\n",
      "Epoch 4/15\n",
      " - 21s - loss: 0.5227 - acc: 0.7355 - mean_absolute_error: 0.3496\n",
      "Epoch 5/15\n",
      " - 22s - loss: 0.5152 - acc: 0.7410 - mean_absolute_error: 0.3436\n",
      "Epoch 6/15\n",
      " - 21s - loss: 0.5095 - acc: 0.7445 - mean_absolute_error: 0.3392\n",
      "Epoch 7/15\n",
      " - 21s - loss: 0.5059 - acc: 0.7471 - mean_absolute_error: 0.3364\n",
      "Epoch 8/15\n",
      " - 24s - loss: 0.5031 - acc: 0.7488 - mean_absolute_error: 0.3343\n",
      "Epoch 9/15\n",
      " - 21s - loss: 0.5010 - acc: 0.7503 - mean_absolute_error: 0.3325\n",
      "Epoch 10/15\n",
      " - 22s - loss: 0.4994 - acc: 0.7513 - mean_absolute_error: 0.3313\n",
      "Epoch 11/15\n",
      " - 24s - loss: 0.4979 - acc: 0.7529 - mean_absolute_error: 0.3301\n",
      "Epoch 12/15\n",
      " - 19s - loss: 0.4967 - acc: 0.7532 - mean_absolute_error: 0.3292\n",
      "Epoch 13/15\n",
      " - 19s - loss: 0.4957 - acc: 0.7541 - mean_absolute_error: 0.3284\n",
      "Epoch 14/15\n",
      " - 19s - loss: 0.4946 - acc: 0.7547 - mean_absolute_error: 0.3276\n",
      "Epoch 15/15\n",
      " - 19s - loss: 0.4938 - acc: 0.7551 - mean_absolute_error: 0.3269\n",
      "500000/500000 [==============================] - 7s 13us/step\n",
      "           Test Loss: 0.4947\n",
      "       Test accuracy: 0.7547\n",
      "            Test mae: 0.3296\n",
      "         Test ROCAUC: 0.8372\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 1\n",
      "Epoch 1/15\n",
      " - 19s - loss: 0.5865 - acc: 0.6844 - mean_absolute_error: 0.4023\n",
      "Epoch 2/15\n",
      " - 19s - loss: 0.5473 - acc: 0.7181 - mean_absolute_error: 0.3692\n",
      "Epoch 3/15\n",
      " - 19s - loss: 0.5301 - acc: 0.7299 - mean_absolute_error: 0.3553\n",
      "Epoch 4/15\n",
      " - 18s - loss: 0.5215 - acc: 0.7363 - mean_absolute_error: 0.3484\n",
      "Epoch 5/15\n",
      " - 19s - loss: 0.5173 - acc: 0.7389 - mean_absolute_error: 0.3450\n",
      "Epoch 6/15\n",
      " - 19s - loss: 0.5143 - acc: 0.7411 - mean_absolute_error: 0.3428\n",
      "Epoch 7/15\n",
      " - 19s - loss: 0.5123 - acc: 0.7426 - mean_absolute_error: 0.3411\n",
      "Epoch 8/15\n",
      " - 19s - loss: 0.5103 - acc: 0.7439 - mean_absolute_error: 0.3395\n",
      "Epoch 9/15\n",
      " - 19s - loss: 0.5086 - acc: 0.7451 - mean_absolute_error: 0.3381\n",
      "Epoch 10/15\n",
      " - 19s - loss: 0.5075 - acc: 0.7456 - mean_absolute_error: 0.3373\n",
      "Epoch 11/15\n",
      " - 19s - loss: 0.5063 - acc: 0.7463 - mean_absolute_error: 0.3363\n",
      "Epoch 12/15\n",
      " - 19s - loss: 0.5054 - acc: 0.7470 - mean_absolute_error: 0.3356\n",
      "Epoch 13/15\n",
      " - 19s - loss: 0.5043 - acc: 0.7478 - mean_absolute_error: 0.3348\n",
      "Epoch 14/15\n",
      " - 18s - loss: 0.5037 - acc: 0.7487 - mean_absolute_error: 0.3342\n",
      "Epoch 15/15\n",
      " - 19s - loss: 0.5031 - acc: 0.7486 - mean_absolute_error: 0.3338\n",
      "500000/500000 [==============================] - 6s 12us/step\n",
      "           Test Loss: 0.5012\n",
      "       Test accuracy: 0.749\n",
      "            Test mae: 0.3341\n",
      "         Test ROCAUC: 0.8321\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 2\n",
      "Epoch 1/15\n",
      " - 20s - loss: 0.5922 - acc: 0.6794 - mean_absolute_error: 0.4070\n",
      "Epoch 2/15\n",
      " - 19s - loss: 0.5517 - acc: 0.7147 - mean_absolute_error: 0.3726\n",
      "Epoch 3/15\n",
      " - 19s - loss: 0.5325 - acc: 0.7281 - mean_absolute_error: 0.3571\n",
      "Epoch 4/15\n",
      " - 19s - loss: 0.5226 - acc: 0.7353 - mean_absolute_error: 0.3492\n",
      "Epoch 5/15\n",
      " - 19s - loss: 0.5175 - acc: 0.7388 - mean_absolute_error: 0.3451\n",
      "Epoch 6/15\n",
      " - 19s - loss: 0.5141 - acc: 0.7409 - mean_absolute_error: 0.3425\n",
      "Epoch 7/15\n",
      " - 19s - loss: 0.5117 - acc: 0.7429 - mean_absolute_error: 0.3405\n",
      "Epoch 8/15\n",
      " - 19s - loss: 0.5099 - acc: 0.7443 - mean_absolute_error: 0.3391\n",
      "Epoch 9/15\n",
      " - 19s - loss: 0.5083 - acc: 0.7455 - mean_absolute_error: 0.3378\n",
      "Epoch 10/15\n",
      " - 19s - loss: 0.5071 - acc: 0.7462 - mean_absolute_error: 0.3368\n",
      "Epoch 11/15\n",
      " - 19s - loss: 0.5062 - acc: 0.7466 - mean_absolute_error: 0.3360\n",
      "Epoch 12/15\n",
      " - 19s - loss: 0.5053 - acc: 0.7472 - mean_absolute_error: 0.3353\n",
      "Epoch 13/15\n",
      " - 19s - loss: 0.5048 - acc: 0.7480 - mean_absolute_error: 0.3348\n",
      "Epoch 14/15\n",
      " - 19s - loss: 0.5042 - acc: 0.7483 - mean_absolute_error: 0.3342\n",
      "Epoch 15/15\n",
      " - 19s - loss: 0.5036 - acc: 0.7480 - mean_absolute_error: 0.3338\n",
      "500000/500000 [==============================] - 6s 13us/step\n",
      "           Test Loss: 0.5008\n",
      "       Test accuracy: 0.7505\n",
      "            Test mae: 0.3321\n",
      "         Test ROCAUC: 0.8325\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 3\n",
      "Epoch 1/15\n",
      " - 23s - loss: 0.5885 - acc: 0.6823 - mean_absolute_error: 0.4041\n",
      "Epoch 2/15\n",
      " - 22s - loss: 0.5480 - acc: 0.7176 - mean_absolute_error: 0.3702\n",
      "Epoch 3/15\n",
      " - 20s - loss: 0.5323 - acc: 0.7290 - mean_absolute_error: 0.3578\n",
      "Epoch 4/15\n",
      " - 20s - loss: 0.5228 - acc: 0.7353 - mean_absolute_error: 0.3503\n",
      "Epoch 5/15\n",
      " - 20s - loss: 0.5165 - acc: 0.7397 - mean_absolute_error: 0.3454\n",
      "Epoch 6/15\n",
      " - 22s - loss: 0.5127 - acc: 0.7422 - mean_absolute_error: 0.3424\n",
      "Epoch 7/15\n",
      " - 20s - loss: 0.5103 - acc: 0.7439 - mean_absolute_error: 0.3405\n",
      "Epoch 8/15\n",
      " - 20s - loss: 0.5083 - acc: 0.7453 - mean_absolute_error: 0.3390\n",
      "Epoch 9/15\n",
      " - 21s - loss: 0.5066 - acc: 0.7463 - mean_absolute_error: 0.3377\n",
      "Epoch 10/15\n",
      " - 28s - loss: 0.5054 - acc: 0.7470 - mean_absolute_error: 0.3367\n",
      "Epoch 11/15\n",
      " - 22s - loss: 0.5043 - acc: 0.7479 - mean_absolute_error: 0.3359\n",
      "Epoch 12/15\n",
      " - 33s - loss: 0.5032 - acc: 0.7484 - mean_absolute_error: 0.3350\n",
      "Epoch 13/15\n",
      " - 22s - loss: 0.5023 - acc: 0.7497 - mean_absolute_error: 0.3343\n",
      "Epoch 14/15\n",
      " - 22s - loss: 0.5017 - acc: 0.7497 - mean_absolute_error: 0.3339\n",
      "Epoch 15/15\n",
      " - 20s - loss: 0.5009 - acc: 0.7501 - mean_absolute_error: 0.3332\n",
      "500000/500000 [==============================] - 7s 13us/step\n",
      "           Test Loss: 0.4987\n",
      "       Test accuracy: 0.7512\n",
      "            Test mae: 0.3321\n",
      "         Test ROCAUC: 0.8338\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 4\n",
      "Epoch 1/15\n",
      " - 23s - loss: 0.6446 - acc: 0.6268 - mean_absolute_error: 0.4531\n",
      "Epoch 2/15\n",
      " - 23s - loss: 0.6409 - acc: 0.6351 - mean_absolute_error: 0.4500\n",
      "Epoch 3/15\n",
      " - 20s - loss: 0.6402 - acc: 0.6365 - mean_absolute_error: 0.4494\n",
      "Epoch 4/15\n",
      " - 20s - loss: 0.6400 - acc: 0.6369 - mean_absolute_error: 0.4492\n",
      "Epoch 5/15\n",
      " - 22s - loss: 0.6398 - acc: 0.6373 - mean_absolute_error: 0.4489\n",
      "Epoch 6/15\n",
      " - 22s - loss: 0.6396 - acc: 0.6377 - mean_absolute_error: 0.4489\n",
      "Epoch 7/15\n",
      " - 25s - loss: 0.6395 - acc: 0.6379 - mean_absolute_error: 0.4487\n",
      "Epoch 8/15\n",
      " - 22s - loss: 0.6394 - acc: 0.6382 - mean_absolute_error: 0.4486\n",
      "Epoch 9/15\n",
      " - 21s - loss: 0.6394 - acc: 0.6382 - mean_absolute_error: 0.4486\n",
      "Epoch 10/15\n",
      " - 20s - loss: 0.6393 - acc: 0.6384 - mean_absolute_error: 0.4486\n",
      "Epoch 11/15\n",
      " - 22s - loss: 0.6393 - acc: 0.6388 - mean_absolute_error: 0.4485\n",
      "Epoch 12/15\n",
      " - 24s - loss: 0.6392 - acc: 0.6387 - mean_absolute_error: 0.4485\n",
      "Epoch 13/15\n",
      " - 21s - loss: 0.6391 - acc: 0.6389 - mean_absolute_error: 0.4484\n",
      "Epoch 14/15\n",
      " - 20s - loss: 0.6392 - acc: 0.6392 - mean_absolute_error: 0.4484\n",
      "Epoch 15/15\n",
      " - 20s - loss: 0.6391 - acc: 0.6389 - mean_absolute_error: 0.4484\n",
      "500000/500000 [==============================] - 7s 14us/step\n",
      "           Test Loss: 0.6384\n",
      "       Test accuracy: 0.6403\n",
      "            Test mae: 0.4502\n",
      "         Test ROCAUC: 0.6829\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 5\n",
      "Epoch 1/15\n",
      " - 25s - loss: 0.5945 - acc: 0.6782 - mean_absolute_error: 0.4082\n",
      "Epoch 2/15\n",
      " - 22s - loss: 0.5651 - acc: 0.7045 - mean_absolute_error: 0.3825\n",
      "Epoch 3/15\n",
      " - 20s - loss: 0.5536 - acc: 0.7139 - mean_absolute_error: 0.3728\n",
      "Epoch 4/15\n",
      " - 20s - loss: 0.5438 - acc: 0.7217 - mean_absolute_error: 0.3646\n",
      "Epoch 5/15\n",
      " - 20s - loss: 0.5380 - acc: 0.7256 - mean_absolute_error: 0.3598\n",
      "Epoch 6/15\n",
      " - 20s - loss: 0.5345 - acc: 0.7282 - mean_absolute_error: 0.3570\n",
      "Epoch 7/15\n",
      " - 20s - loss: 0.5322 - acc: 0.7293 - mean_absolute_error: 0.3551\n",
      "Epoch 8/15\n",
      " - 20s - loss: 0.5310 - acc: 0.7308 - mean_absolute_error: 0.3540\n",
      "Epoch 9/15\n",
      " - 20s - loss: 0.5295 - acc: 0.7313 - mean_absolute_error: 0.3528\n",
      "Epoch 10/15\n",
      " - 20s - loss: 0.5285 - acc: 0.7321 - mean_absolute_error: 0.3521\n",
      "Epoch 11/15\n",
      " - 21s - loss: 0.5274 - acc: 0.7324 - mean_absolute_error: 0.3512\n",
      "Epoch 12/15\n",
      " - 42s - loss: 0.5265 - acc: 0.7334 - mean_absolute_error: 0.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      " - 28s - loss: 0.5258 - acc: 0.7343 - mean_absolute_error: 0.3497\n",
      "Epoch 14/15\n",
      " - 23s - loss: 0.5250 - acc: 0.7341 - mean_absolute_error: 0.3491\n",
      "Epoch 15/15\n",
      " - 19s - loss: 0.5243 - acc: 0.7349 - mean_absolute_error: 0.3488\n",
      "500000/500000 [==============================] - 6s 13us/step\n",
      "           Test Loss: 0.5194\n",
      "       Test accuracy: 0.7385\n",
      "            Test mae: 0.3427\n",
      "         Test ROCAUC: 0.8183\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 6\n",
      "Epoch 1/15\n",
      " - 20s - loss: 0.5910 - acc: 0.6803 - mean_absolute_error: 0.4059\n",
      "Epoch 2/15\n",
      " - 19s - loss: 0.5543 - acc: 0.7130 - mean_absolute_error: 0.3744\n",
      "Epoch 3/15\n",
      " - 20s - loss: 0.5397 - acc: 0.7236 - mean_absolute_error: 0.3625\n",
      "Epoch 4/15\n",
      " - 19s - loss: 0.5278 - acc: 0.7322 - mean_absolute_error: 0.3531\n",
      "Epoch 5/15\n",
      " - 19s - loss: 0.5196 - acc: 0.7377 - mean_absolute_error: 0.3465\n",
      "Epoch 6/15\n",
      " - 19s - loss: 0.5140 - acc: 0.7410 - mean_absolute_error: 0.3422\n",
      "Epoch 7/15\n",
      " - 26s - loss: 0.5105 - acc: 0.7438 - mean_absolute_error: 0.3393\n",
      "Epoch 8/15\n",
      " - 23s - loss: 0.5080 - acc: 0.7454 - mean_absolute_error: 0.3375\n",
      "Epoch 9/15\n",
      " - 19s - loss: 0.5060 - acc: 0.7473 - mean_absolute_error: 0.3358\n",
      "Epoch 10/15\n",
      " - 22s - loss: 0.5050 - acc: 0.7476 - mean_absolute_error: 0.3348\n",
      "Epoch 11/15\n",
      " - 20s - loss: 0.5038 - acc: 0.7484 - mean_absolute_error: 0.3339\n",
      "Epoch 12/15\n",
      " - 24s - loss: 0.5027 - acc: 0.7487 - mean_absolute_error: 0.3329\n",
      "Epoch 13/15\n",
      " - 21s - loss: 0.5020 - acc: 0.7495 - mean_absolute_error: 0.3323\n",
      "Epoch 14/15\n",
      " - 22s - loss: 0.5016 - acc: 0.7503 - mean_absolute_error: 0.3318\n",
      "Epoch 15/15\n",
      " - 23s - loss: 0.5011 - acc: 0.7503 - mean_absolute_error: 0.3314\n",
      "500000/500000 [==============================] - 7s 14us/step\n",
      "           Test Loss: 0.5008\n",
      "       Test accuracy: 0.7511\n",
      "            Test mae: 0.334\n",
      "         Test ROCAUC: 0.8331\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 7\n",
      "Epoch 1/15\n",
      " - 24s - loss: 0.5931 - acc: 0.6793 - mean_absolute_error: 0.4070\n",
      "Epoch 2/15\n",
      " - 21s - loss: 0.5610 - acc: 0.7069 - mean_absolute_error: 0.3792\n",
      "Epoch 3/15\n",
      " - 22s - loss: 0.5492 - acc: 0.7167 - mean_absolute_error: 0.3693\n",
      "Epoch 4/15\n",
      " - 22s - loss: 0.5382 - acc: 0.7251 - mean_absolute_error: 0.3601\n",
      "Epoch 5/15\n",
      " - 21s - loss: 0.5294 - acc: 0.7308 - mean_absolute_error: 0.3531\n",
      "Epoch 6/15\n",
      " - 22s - loss: 0.5240 - acc: 0.7345 - mean_absolute_error: 0.3488\n",
      "Epoch 7/15\n",
      " - 21s - loss: 0.5203 - acc: 0.7370 - mean_absolute_error: 0.3458\n",
      "Epoch 8/15\n",
      " - 21s - loss: 0.5179 - acc: 0.7388 - mean_absolute_error: 0.3438\n",
      "Epoch 9/15\n",
      " - 22s - loss: 0.5152 - acc: 0.7405 - mean_absolute_error: 0.3418\n",
      "Epoch 10/15\n",
      " - 21s - loss: 0.5136 - acc: 0.7416 - mean_absolute_error: 0.3406\n",
      "Epoch 11/15\n",
      " - 21s - loss: 0.5121 - acc: 0.7426 - mean_absolute_error: 0.3394\n",
      "Epoch 12/15\n",
      " - 21s - loss: 0.5108 - acc: 0.7437 - mean_absolute_error: 0.3384\n",
      "Epoch 13/15\n",
      " - 21s - loss: 0.5095 - acc: 0.7443 - mean_absolute_error: 0.3373\n",
      "Epoch 14/15\n",
      " - 21s - loss: 0.5083 - acc: 0.7452 - mean_absolute_error: 0.3364\n",
      "Epoch 15/15\n",
      " - 21s - loss: 0.5074 - acc: 0.7459 - mean_absolute_error: 0.3358\n",
      "500000/500000 [==============================] - 8s 15us/step\n",
      "           Test Loss: 0.506\n",
      "       Test accuracy: 0.7473\n",
      "            Test mae: 0.3328\n",
      "         Test ROCAUC: 0.8287\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 8\n",
      "Epoch 1/15\n",
      " - 22s - loss: 0.5941 - acc: 0.6785 - mean_absolute_error: 0.4082\n",
      "Epoch 2/15\n",
      " - 24s - loss: 0.5584 - acc: 0.7101 - mean_absolute_error: 0.3773\n",
      "Epoch 3/15\n",
      " - 29s - loss: 0.5432 - acc: 0.7211 - mean_absolute_error: 0.3644\n",
      "Epoch 4/15\n",
      " - 22s - loss: 0.5363 - acc: 0.7257 - mean_absolute_error: 0.3587\n",
      "Epoch 5/15\n",
      " - 20s - loss: 0.5327 - acc: 0.7287 - mean_absolute_error: 0.3559\n",
      "Epoch 6/15\n",
      " - 20s - loss: 0.5305 - acc: 0.7299 - mean_absolute_error: 0.3540\n",
      "Epoch 7/15\n",
      " - 20s - loss: 0.5289 - acc: 0.7312 - mean_absolute_error: 0.3527\n",
      "Epoch 8/15\n",
      " - 20s - loss: 0.5275 - acc: 0.7325 - mean_absolute_error: 0.3517\n",
      "Epoch 9/15\n",
      " - 20s - loss: 0.5261 - acc: 0.7326 - mean_absolute_error: 0.3506\n",
      "Epoch 10/15\n",
      " - 20s - loss: 0.5252 - acc: 0.7332 - mean_absolute_error: 0.3499\n",
      "Epoch 11/15\n",
      " - 20s - loss: 0.5241 - acc: 0.7339 - mean_absolute_error: 0.3490\n",
      "Epoch 12/15\n",
      " - 20s - loss: 0.5231 - acc: 0.7347 - mean_absolute_error: 0.3483\n",
      "Epoch 13/15\n",
      " - 20s - loss: 0.5225 - acc: 0.7357 - mean_absolute_error: 0.3478\n",
      "Epoch 14/15\n",
      " - 20s - loss: 0.5217 - acc: 0.7357 - mean_absolute_error: 0.3471\n",
      "Epoch 15/15\n",
      " - 20s - loss: 0.5213 - acc: 0.7360 - mean_absolute_error: 0.3469\n",
      "500000/500000 [==============================] - 7s 14us/step\n",
      "           Test Loss: 0.5158\n",
      "       Test accuracy: 0.7392\n",
      "            Test mae: 0.3413\n",
      "         Test ROCAUC: 0.8206\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 9\n",
      "Epoch 1/15\n",
      " - 21s - loss: 0.6023 - acc: 0.6691 - mean_absolute_error: 0.4160\n",
      "Epoch 2/15\n",
      " - 20s - loss: 0.5636 - acc: 0.7048 - mean_absolute_error: 0.3828\n",
      "Epoch 3/15\n",
      " - 21s - loss: 0.5498 - acc: 0.7154 - mean_absolute_error: 0.3716\n",
      "Epoch 4/15\n",
      " - 20s - loss: 0.5355 - acc: 0.7260 - mean_absolute_error: 0.3600\n",
      "Epoch 5/15\n",
      " - 20s - loss: 0.5273 - acc: 0.7322 - mean_absolute_error: 0.3533\n",
      "Epoch 6/15\n",
      " - 21s - loss: 0.5208 - acc: 0.7364 - mean_absolute_error: 0.3483\n",
      "Epoch 7/15\n",
      " - 20s - loss: 0.5153 - acc: 0.7400 - mean_absolute_error: 0.3439\n",
      "Epoch 8/15\n",
      " - 20s - loss: 0.5122 - acc: 0.7421 - mean_absolute_error: 0.3416\n",
      "Epoch 9/15\n",
      " - 20s - loss: 0.5099 - acc: 0.7437 - mean_absolute_error: 0.3397\n",
      "Epoch 10/15\n",
      " - 20s - loss: 0.5081 - acc: 0.7450 - mean_absolute_error: 0.3383\n",
      "Epoch 11/15\n",
      " - 20s - loss: 0.5065 - acc: 0.7459 - mean_absolute_error: 0.3370\n",
      "Epoch 12/15\n",
      " - 21s - loss: 0.5050 - acc: 0.7470 - mean_absolute_error: 0.3360\n",
      "Epoch 13/15\n",
      " - 20s - loss: 0.5037 - acc: 0.7479 - mean_absolute_error: 0.3348\n",
      "Epoch 14/15\n",
      " - 20s - loss: 0.5027 - acc: 0.7487 - mean_absolute_error: 0.3341\n",
      "Epoch 15/15\n",
      " - 20s - loss: 0.5019 - acc: 0.7492 - mean_absolute_error: 0.3335\n",
      "500000/500000 [==============================] - 7s 15us/step\n",
      "           Test Loss: 0.5062\n",
      "       Test accuracy: 0.7468\n",
      "            Test mae: 0.3357\n",
      "         Test ROCAUC: 0.8294\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 10\n",
      "Epoch 1/15\n",
      " - 21s - loss: 0.5887 - acc: 0.6827 - mean_absolute_error: 0.4033\n",
      "Epoch 2/15\n",
      " - 21s - loss: 0.5532 - acc: 0.7132 - mean_absolute_error: 0.3731\n",
      "Epoch 3/15\n",
      " - 20s - loss: 0.5404 - acc: 0.7227 - mean_absolute_error: 0.3627\n",
      "Epoch 4/15\n",
      " - 20s - loss: 0.5285 - acc: 0.7314 - mean_absolute_error: 0.3532\n",
      "Epoch 5/15\n",
      " - 20s - loss: 0.5200 - acc: 0.7373 - mean_absolute_error: 0.3466\n",
      "Epoch 6/15\n",
      " - 20s - loss: 0.5134 - acc: 0.7412 - mean_absolute_error: 0.3416\n",
      "Epoch 7/15\n",
      " - 20s - loss: 0.5094 - acc: 0.7440 - mean_absolute_error: 0.3385\n",
      "Epoch 8/15\n",
      " - 21s - loss: 0.5066 - acc: 0.7459 - mean_absolute_error: 0.3364\n",
      "Epoch 9/15\n",
      " - 20s - loss: 0.5044 - acc: 0.7477 - mean_absolute_error: 0.3347\n",
      "Epoch 10/15\n",
      " - 21s - loss: 0.5027 - acc: 0.7486 - mean_absolute_error: 0.3333\n",
      "Epoch 11/15\n",
      " - 20s - loss: 0.5010 - acc: 0.7496 - mean_absolute_error: 0.3319\n",
      "Epoch 12/15\n",
      " - 20s - loss: 0.4994 - acc: 0.7507 - mean_absolute_error: 0.3308\n",
      "Epoch 13/15\n",
      " - 20s - loss: 0.4982 - acc: 0.7514 - mean_absolute_error: 0.3298\n",
      "Epoch 14/15\n",
      " - 21s - loss: 0.4972 - acc: 0.7524 - mean_absolute_error: 0.3290\n",
      "Epoch 15/15\n",
      " - 20s - loss: 0.4961 - acc: 0.7531 - mean_absolute_error: 0.3281\n",
      "500000/500000 [==============================] - 8s 15us/step\n",
      "           Test Loss: 0.5014\n",
      "       Test accuracy: 0.7506\n",
      "            Test mae: 0.3296\n",
      "         Test ROCAUC: 0.8326\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "LAYER CONFIG: 11\n",
      "Epoch 1/15\n",
      " - 22s - loss: 0.5844 - acc: 0.6862 - mean_absolute_error: 0.4004\n",
      "Epoch 2/15\n",
      " - 22s - loss: 0.5493 - acc: 0.7165 - mean_absolute_error: 0.3706\n",
      "Epoch 3/15\n",
      " - 30s - loss: 0.5372 - acc: 0.7254 - mean_absolute_error: 0.3606\n",
      "Epoch 4/15\n",
      " - 24s - loss: 0.5269 - acc: 0.7325 - mean_absolute_error: 0.3524\n",
      "Epoch 5/15\n",
      " - 27s - loss: 0.5195 - acc: 0.7374 - mean_absolute_error: 0.3467\n",
      "Epoch 6/15\n",
      " - 26s - loss: 0.5133 - acc: 0.7417 - mean_absolute_error: 0.3419\n",
      "Epoch 7/15\n",
      " - 22s - loss: 0.5078 - acc: 0.7453 - mean_absolute_error: 0.3376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      " - 25s - loss: 0.5045 - acc: 0.7474 - mean_absolute_error: 0.3351\n",
      "Epoch 9/15\n",
      " - 30s - loss: 0.5021 - acc: 0.7493 - mean_absolute_error: 0.3331\n",
      "Epoch 10/15\n",
      " - 22s - loss: 0.5002 - acc: 0.7504 - mean_absolute_error: 0.3317\n",
      "Epoch 11/15\n",
      " - 22s - loss: 0.4987 - acc: 0.7518 - mean_absolute_error: 0.3305\n",
      "Epoch 12/15\n",
      " - 22s - loss: 0.4971 - acc: 0.7526 - mean_absolute_error: 0.3293\n",
      "Epoch 13/15\n",
      " - 23s - loss: 0.4961 - acc: 0.7531 - mean_absolute_error: 0.3284\n",
      "Epoch 14/15\n",
      " - 22s - loss: 0.4950 - acc: 0.7542 - mean_absolute_error: 0.3276\n",
      "Epoch 15/15\n",
      " - 22s - loss: 0.4940 - acc: 0.7547 - mean_absolute_error: 0.3268\n",
      "500000/500000 [==============================] - 8s 15us/step\n",
      "           Test Loss: 0.495\n",
      "       Test accuracy: 0.7534\n",
      "            Test mae: 0.3283\n",
      "         Test ROCAUC: 0.8368\n"
     ]
    }
   ],
   "source": [
    "#previous exploration of activation functions did not include the absence of a function!\n",
    "#a linear-transformation only layer is a possibility and so is tried here.\n",
    "layer_list = [[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, \"relu\", \"relu\", \"relu\"])], #0.836\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [\"tanh\", None, \"relu\", \"relu\"])], #0.8313\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [\"tanh\", \"relu\", None, \"relu\"])], #0.8322\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [\"tanh\", \"relu\", \"relu\", None])], #0.8327\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, None, None, None])], #0.6829\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, None, None, \"relu\"])], #0.8188\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, \"relu\", None, \"relu\"])], #0.8331\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, \"tanh\", None, \"relu\"])], #0.8306\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [\"tanh\", None, None, \"relu\"])], #0.8197\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, \"tanh\", \"tanh\", \"tanh\"])], #0.8323\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, \"tanh\", \"tanh\", \"relu\"])], #0.8321\n",
    "\t[[i, \"orthogonal\", x] for i, x in zip([20, 100,100,140], [None, \"tanh\", \"relu\", \"relu\"])] #0.8355\n",
    "\t]\n",
    "\n",
    "sdat = []\n",
    "opt = Adadelta()\n",
    "for i, layer in enumerate(layer_list[0:]):\n",
    "\tprint(\"-*\"*40)\n",
    "\tprint(\"LAYER CONFIG: {}\".format(i))\n",
    "\tnp.random.seed(128)\n",
    "\tsdat.append(model_test(layer, opt, epochs=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is our best model after all of that (it was trained first in the above)\n",
    "m_best = Sequential()\n",
    "m_best.add(Dense(20, input_dim = x.shape[1], kernel_initializer = 'orthogonal', activation = None))\n",
    "m_best.add(Dense(100, kernel_initializer = 'orthogonal', activation = \"relu\"))\n",
    "m_best.add(Dense(100, kernel_initializer = 'orthogonal', activation = \"relu\"))\n",
    "m_best.add(Dense(140, kernel_initializer = 'orthogonal', activation = \"relu\"))\n",
    "m_best.add(Dense(1, kernel_initializer = 'orthogonal', activation = 'sigmoid'))\n",
    "\n",
    "m_best.compile(loss = 'binary_crossentropy', metrics = ['accuracy', 'mae'], optimizer = Adadelta())\n",
    "\n",
    "# m_best.fit(x, y, epochs = 15, batch_size = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
