{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Classification Models\n",
    "Michael Murrietta\n",
    "\n",
    "3/17/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Classification is a fundamental task of many machine learning and statistical algorithms. An effort is given here to compare three different models on the task of classifying email messages as spam or ham using a single dataset. Since a subset of all available models is used for the task emphasis is made on the method of how to compare such models. Naive Bayes, Classification Trees from the CART algorithm, and random forests will be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Problem from 10.8 \n",
    "Compare Naive Bayes, CART, and one other algorithm.\n",
    "A comparison means at least a 5 fold CV tuned model for each.\n",
    "Which has the best precision\n",
    "Which has the best recall\n",
    "Which has the best accuracy\n",
    "Which has the best F1\n",
    "Based on those questions which model performs 'best' aka which would you implement if given the choice of 1 and only 1 \n",
    "(no secret option D of ensemble them all)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "Naive Bayes was performed a la Nolan and Lang. Cart was also done. Random forests were done too.\n",
    "\n",
    "Metrics used:\n",
    "+ Precision\n",
    "+ Recall (True Positive Rate)\n",
    "+ Accuracy\n",
    "+ F1 score\n",
    "+ F2 score: I wanted to use this since it places more importance on negative cases. The rationale is that my preference as an email user would be to get all of my non-spam messages even at the cost of a few spam messages making into my inbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions that follow are due to Nolan and Lang from chapter 3 of their text (Nolan & Lang, 2015) and are used to read in and process the messages from a sub directory named `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in functions and stopwords for naive Bayes\n",
    "library(tm)\n",
    "stopWords = stopwords()\n",
    "cleanSW = tolower(gsub(\"[[:punct:]0-9[:blank:]]+\", \" \", stopWords))\n",
    "SWords = unlist(strsplit(cleanSW, \"[[:blank:]]+\"))\n",
    "SWords = SWords[ nchar(SWords) > 1 ]\n",
    "stopWords = unique(SWords)\n",
    "\n",
    "splitMessage = function(msg) {\n",
    "  splitPoint = match(\"\", msg)\n",
    "  header = msg[1:(splitPoint-1)]\n",
    "  body = msg[ -(1:splitPoint) ]\n",
    "  return(list(header = header, body = body))\n",
    "}\n",
    "\n",
    "getBoundary = function(header) {\n",
    "  boundaryIdx = grep(\"boundary=\", header)\n",
    "  boundary = gsub('\"', \"\", header[boundaryIdx])\n",
    "  gsub(\".*boundary= *([^;]*);?.*\", \"\\\\1\", boundary)\n",
    "}\n",
    "\n",
    "dropAttach = function(body, boundary){\n",
    "  \n",
    "  bString = paste(\"--\", boundary, sep = \"\")\n",
    "  bStringLocs = which(bString == body)\n",
    "  \n",
    "  if (length(bStringLocs) <= 1) return(body)\n",
    "  \n",
    "  eString = paste(\"--\", boundary, \"--\", sep = \"\")\n",
    "  eStringLoc = which(eString == body)\n",
    "  if (length(eStringLoc) == 0) \n",
    "    return(body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1)])\n",
    "  \n",
    "  n = length(body)\n",
    "  if (eStringLoc < n) \n",
    "     return( body[ c( (bStringLocs[1] + 1) : (bStringLocs[2] - 1), \n",
    "                    ( (eStringLoc + 1) : n )) ] )\n",
    "  \n",
    "  return( body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1) ])\n",
    "}\n",
    "    \n",
    "cleanText =\n",
    "function(msg)   {\n",
    "  tolower(gsub(\"[[:punct:]0-9[:space:][:blank:]]+\", \" \", msg))\n",
    "}\n",
    "\n",
    "findMsgWords = \n",
    "function(msg, stopWords) {\n",
    " if(is.null(msg))\n",
    "  return(character())\n",
    "\n",
    " words = unique(unlist(strsplit(cleanText(msg), \"[[:blank:]\\t]+\")))\n",
    " \n",
    " # drop empty and 1 letter words\n",
    " words = words[ nchar(words) > 1]\n",
    " words = words[ !( words %in% stopWords) ]\n",
    " invisible(words)\n",
    "}\n",
    "\n",
    "processAllWords = function(dirName, stopWords)\n",
    "{\n",
    "       # read all files in the directory\n",
    "  fileNames = list.files(dirName, full.names = TRUE)\n",
    "       # drop files that are not email, i.e., cmds\n",
    "  notEmail = grep(\"cmds$\", fileNames)\n",
    "  if ( length(notEmail) > 0) fileNames = fileNames[ - notEmail ]\n",
    "\n",
    "  messages = lapply(fileNames, readLines, encoding = \"latin1\")\n",
    "  \n",
    "       # split header and body\n",
    "  emailSplit = lapply(messages, splitMessage)\n",
    "       # put body and header in own lists\n",
    "  bodyList = lapply(emailSplit, function(msg) msg$body)\n",
    "  headerList = lapply(emailSplit, function(msg) msg$header)\n",
    "  rm(emailSplit)\n",
    "  \n",
    "       # determine which messages have attachments\n",
    "  hasAttach = sapply(headerList, function(header) {\n",
    "    CTloc = grep(\"Content-Type\", header)\n",
    "    if (length(CTloc) == 0) return(0)\n",
    "    multi = grep(\"multi\", tolower(header[CTloc])) \n",
    "    if (length(multi) == 0) return(0)\n",
    "    multi\n",
    "  })\n",
    "  \n",
    "  hasAttach = which(hasAttach > 0)\n",
    "  \n",
    "       # find boundary strings for messages with attachments\n",
    "  boundaries = sapply(headerList[hasAttach], getBoundary)\n",
    "  \n",
    "       # drop attachments from message body\n",
    "  bodyList[hasAttach] = mapply(dropAttach, bodyList[hasAttach], \n",
    "                               boundaries, SIMPLIFY = FALSE)\n",
    "  \n",
    "       # extract words from body\n",
    "  msgWordsList = lapply(bodyList, findMsgWords, stopWords)\n",
    "  \n",
    "  invisible(msgWordsList)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some other constants to allow us to use the above functions when processing messages\n",
    "#for naive Bayes\n",
    "spamPath = \"./data\"\n",
    "dirNames = list.files(path = paste(spamPath, \"messages\",\n",
    "                      sep = .Platform$file.sep))\n",
    "fullDirNames = paste(spamPath, \"messages\", dirNames, \n",
    "                     sep = .Platform$file.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in FUN(X[[i]], ...):\n",
      "\"incomplete final line found on './data/messages/hard_ham/00228.0eaef7857bbbf3ebf5edbbdae2b30493'\"Warning message in FUN(X[[i]], ...):\n",
      "\"incomplete final line found on './data/messages/hard_ham/0231.7c6cc716ce3f3bfad7130dd3c8d7b072'\"Warning message in FUN(X[[i]], ...):\n",
      "\"incomplete final line found on './data/messages/hard_ham/0250.7c6cc716ce3f3bfad7130dd3c8d7b072'\"Warning message in FUN(X[[i]], ...):\n",
      "\"incomplete final line found on './data/messages/spam/00136.faa39d8e816c70f23b4bb8758d8a74f0'\"Warning message in FUN(X[[i]], ...):\n",
      "\"incomplete final line found on './data/messages/spam/0143.260a940290dcb61f9327b224a368d4af'\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 5051 1400  500 1000 1397\n"
     ]
    }
   ],
   "source": [
    "#now read in and process the raw messages using the above functions\n",
    "msgWordsList = lapply(fullDirNames, processAllWords, \n",
    "                      stopWords = stopWords) \n",
    "\n",
    "#get number of messages in each directory\n",
    "numMsgs = sapply(msgWordsList, length)\n",
    "print(numMsgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have `msgWordsList` which is a list of 5 sub lists corresponding to the directories from which they came. The directories are: `easy_ham`, `easy_ham_2`, `hard_ham`, `spam`, and `spam_2`. Each sub list is a list of processed messages from the respective directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create logical labels for each message based on which folder they are in:\n",
    "#the first 3 are ham the last 2 are spam\n",
    "isSpam = rep(c(FALSE, FALSE, FALSE, TRUE, TRUE), numMsgs)\n",
    "\n",
    "#flatten into a single list of msgs\n",
    "msgWordsList = unlist(msgWordsList, recursive = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are again from the text (Nolan & Lang, 2015) and are used to train a model given some training messages (`computeFreqs`) and then compute the log likelihood ratio for a given message `computeMsgLLR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computeFreqs =\n",
    "function(wordsList, spam, bow = unique(unlist(wordsList)))\n",
    "{\n",
    "   # create a matrix for spam, ham, and log odds\n",
    "  wordTable = matrix(0.5, nrow = 4, ncol = length(bow), \n",
    "                     dimnames = list(c(\"spam\", \"ham\", \n",
    "                                        \"presentLogOdds\", \n",
    "                                        \"absentLogOdds\"),  bow))\n",
    "\n",
    "   # For each spam message, add 1 to counts for words in message\n",
    "  counts.spam = table(unlist(lapply(wordsList[spam], unique)))\n",
    "  wordTable[\"spam\", names(counts.spam)] = counts.spam + .5\n",
    "\n",
    "   # Similarly for ham messages\n",
    "  counts.ham = table(unlist(lapply(wordsList[!spam], unique)))  \n",
    "  wordTable[\"ham\", names(counts.ham)] = counts.ham + .5  \n",
    "\n",
    "\n",
    "   # Find the total number of spam and ham\n",
    "  numSpam = sum(spam)\n",
    "  numHam = length(spam) - numSpam\n",
    "\n",
    "   # Prob(word|spam) and Prob(word | ham)\n",
    "  wordTable[\"spam\", ] = wordTable[\"spam\", ]/(numSpam + .5)\n",
    "  wordTable[\"ham\", ] = wordTable[\"ham\", ]/(numHam + .5)\n",
    "  \n",
    "   # log odds\n",
    "  wordTable[\"presentLogOdds\", ] = \n",
    "     log(wordTable[\"spam\",]) - log(wordTable[\"ham\", ])\n",
    "  wordTable[\"absentLogOdds\", ] = \n",
    "     log((1 - wordTable[\"spam\", ])) - log((1 -wordTable[\"ham\", ]))\n",
    "\n",
    "  invisible(wordTable)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute LLR of a processed message\n",
    "computeMsgLLR = function(words, freqTable) \n",
    "{\n",
    "       # Discards words not in training data.\n",
    "  words = words[!is.na(match(words, colnames(freqTable)))]\n",
    "\n",
    "       # Find which words are present\n",
    "  present = colnames(freqTable) %in% words\n",
    "\n",
    "  sum(freqTable[\"presentLogOdds\", present]) +\n",
    "    sum(freqTable[\"absentLogOdds\", !present])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are adapted from the `typeIErrorRate` function given by Nolan and Lang, these calculate all rates from the 2 x 2 confusion matrix associated with threshold `tau`, the log likelihood ratios `llrVals`, and the labels of spam or not-spam `spam`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Naive Bayes\n",
    "Here we test the naive Bayes method as implemented in the Nolan and Lang's text (Nolan & Lang, 2015) using 10 fold cross validation. Most of the code below is taken from the text but was modified to easily calculate the metrics of interest as well as to produce the ROC plot.\n",
    "\n",
    "The work in chapter 3 of the text suggests that -35 is a choice for threshold that will produce a false positive rate of 0.01 and a false negative rate of about 0.06. The way this was arrived at was by pooling together the out-of-fold false positive/negative rates and then selecting the threshold that accounted for the best false negative rate after subsetting for thresholds that produced a false positive rate of 0.01. This was in effort to select the best threshold for the model independent of the training set used.\n",
    "\n",
    "In this case the threshold of -35 is retained where log likelihood ratios less than or equal to -35 are considered not spam and those with log likelihood ratios greater than -35 are considered to be spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate confusion matrix proportions and some other measures of error\n",
    "#adapted from previous definition but now for a generic vector of predictions and true labels (no threshold needed)\n",
    "falsePosRate = \n",
    "function(yhat, y)\n",
    "{\n",
    "  sum(yhat & !y)/sum(!y) #sum all false positives divide by sum of all actual positives\n",
    "}\n",
    "falseNegRate = \n",
    "function(yhat, y)\n",
    "{\n",
    "  sum(!yhat & y)/sum(y) #sum all false positives divide by sum of all actual positives\n",
    "}\n",
    "truePosRate = \n",
    "function(yhat, y)\n",
    "{\n",
    "  sum(yhat & y)/sum(y)\n",
    "}\n",
    "trueNegRate = \n",
    "function(yhat, y)\n",
    "{\n",
    "  sum(!yhat & !y)/sum(!y) #sum all non-spam that were actually negative, divide by all negatives\n",
    "}\n",
    "#precision is number of true positives divided by number of all predicted positives\n",
    "precision = function(yhat, y)\n",
    "{\n",
    "  sum(yhat & y)/sum(yhat)\n",
    "}\n",
    "#recall is number of true positives divided by number of all actual positives\n",
    "#which is just the true positive rate for which we already have a function to use\n",
    "\n",
    "#f1 score is the harmonic mean of precision and recall\n",
    "f1score = function(yhat, y)\n",
    "{\n",
    "  prec = precision(yhat, y)\n",
    "  rec = truePosRate(yhat, y)\n",
    "  (2*prec*rec)/(prec + rec)\n",
    "}\n",
    "\n",
    "accuracy = function(yhat, y)\n",
    "{\n",
    "  (sum(yhat & y) + sum(!yhat & !y))/length(y)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now collect FPR and TPR for each fold using the suggested threshold from the previous analysis\n",
    "k = 10 #set k\n",
    "numTrain = length(msgWordsList) #get number of training observations\n",
    "partK = sample(numTrain) #randomly sample digits between 1 and numTrain\n",
    "tot = k * floor(numTrain/k) #set the total number of observations we'll use in all k folds, ensures even amounts\n",
    "partK = matrix(partK[1:tot], ncol = k) #matrix using the the first tot items in the vector version of partK\n",
    "\n",
    "testFoldOdds = NULL #a blank vector: we'll append the Odds vectors produced for each test fold\n",
    "for (i in 1:k) {\n",
    "  foldIdx = partK[ , i] #use column i in partK to test, use the rest for training\n",
    "  trainTabFold = computeFreqs(msgWordsList[-foldIdx], isSpam[-foldIdx])\n",
    "  testFoldOdds = c(testFoldOdds, \n",
    "               sapply(msgWordsList[ foldIdx ], computeMsgLLR, trainTabFold))\n",
    "}\n",
    "\n",
    "testFoldSpam = NULL #blank vector that gets the labels for spam or not spam of each test fold\n",
    "for (i in 1:k) {\n",
    "  foldIdx = partK[ , i]\n",
    "  testFoldSpam = c(testFoldSpam, isSpam[foldIdx])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply our threshold to the odds\n",
    "testFoldPred = testFoldOdds > -35\n",
    "#expand the predictions and actual labels into matrices, one column for each set of out-of-sample folds\n",
    "testFoldPred = matrix(testFoldPred, ncol=k)\n",
    "testFoldSpam = matrix(testFoldSpam, ncol=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>fold</th><th scope=col>method</th><th scope=col>tpr</th><th scope=col>fpr</th><th scope=col>prec</th><th scope=col>f1</th><th scope=col>acc</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1                  </td><td>naive_bayes_bow    </td><td>0.960869565217391  </td><td>0.00852272727272727</td><td>0.973568281938326  </td><td>0.967177242888403  </td><td>0.983940042826552  </td></tr>\n",
       "\t<tr><td>2                  </td><td>naive_bayes_bow    </td><td>0.956175298804781  </td><td>0.00878477306002928</td><td>0.975609756097561  </td><td>0.96579476861167   </td><td>0.981798715203426  </td></tr>\n",
       "\t<tr><td>3                  </td><td>naive_bayes_bow    </td><td>0.960352422907489  </td><td>0.0099009900990099 </td><td>0.968888888888889  </td><td>0.964601769911505  </td><td>0.982869379014989  </td></tr>\n",
       "\t<tr><td>4                  </td><td>naive_bayes_bow    </td><td>0.943127962085308  </td><td>0.00276625172890733</td><td>0.990049751243781  </td><td>0.966019417475728  </td><td>0.985010706638116  </td></tr>\n",
       "\t<tr><td>5                  </td><td>naive_bayes_bow    </td><td>0.962655601659751  </td><td>0.00577200577200577</td><td>0.983050847457627  </td><td>0.972746331236897  </td><td>0.986081370449679  </td></tr>\n",
       "\t<tr><td>6                  </td><td>naive_bayes_bow    </td><td>0.975903614457831  </td><td>0.00875912408759124</td><td>0.975903614457831  </td><td>0.975903614457831  </td><td>0.987152034261242  </td></tr>\n",
       "\t<tr><td>7                  </td><td>naive_bayes_bow    </td><td>0.956              </td><td>0.0087719298245614 </td><td>0.975510204081633  </td><td>0.965656565656566  </td><td>0.981798715203426  </td></tr>\n",
       "\t<tr><td>8                  </td><td>naive_bayes_bow    </td><td>0.936254980079681  </td><td>0.00732064421669107</td><td>0.979166666666667  </td><td>0.957230142566191  </td><td>0.977516059957173  </td></tr>\n",
       "\t<tr><td>9                  </td><td>naive_bayes_bow    </td><td>0.956862745098039  </td><td>0.00441826215022091</td><td>0.987854251012146  </td><td>0.97211155378486   </td><td>0.985010706638116  </td></tr>\n",
       "\t<tr><td>10                 </td><td>naive_bayes_bow    </td><td>0.952380952380952  </td><td>0.0113798008534851 </td><td>0.964912280701754  </td><td>0.958605664488017  </td><td>0.9796573875803    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllllll}\n",
       " fold & method & tpr & fpr & prec & f1 & acc\\\\\n",
       "\\hline\n",
       "\t 1                   & naive\\_bayes\\_bow & 0.960869565217391   & 0.00852272727272727 & 0.973568281938326   & 0.967177242888403   & 0.983940042826552  \\\\\n",
       "\t 2                   & naive\\_bayes\\_bow & 0.956175298804781   & 0.00878477306002928 & 0.975609756097561   & 0.96579476861167    & 0.981798715203426  \\\\\n",
       "\t 3                   & naive\\_bayes\\_bow & 0.960352422907489   & 0.0099009900990099  & 0.968888888888889   & 0.964601769911505   & 0.982869379014989  \\\\\n",
       "\t 4                   & naive\\_bayes\\_bow & 0.943127962085308   & 0.00276625172890733 & 0.990049751243781   & 0.966019417475728   & 0.985010706638116  \\\\\n",
       "\t 5                   & naive\\_bayes\\_bow & 0.962655601659751   & 0.00577200577200577 & 0.983050847457627   & 0.972746331236897   & 0.986081370449679  \\\\\n",
       "\t 6                   & naive\\_bayes\\_bow & 0.975903614457831   & 0.00875912408759124 & 0.975903614457831   & 0.975903614457831   & 0.987152034261242  \\\\\n",
       "\t 7                   & naive\\_bayes\\_bow & 0.956               & 0.0087719298245614  & 0.975510204081633   & 0.965656565656566   & 0.981798715203426  \\\\\n",
       "\t 8                   & naive\\_bayes\\_bow & 0.936254980079681   & 0.00732064421669107 & 0.979166666666667   & 0.957230142566191   & 0.977516059957173  \\\\\n",
       "\t 9                   & naive\\_bayes\\_bow & 0.956862745098039   & 0.00441826215022091 & 0.987854251012146   & 0.97211155378486    & 0.985010706638116  \\\\\n",
       "\t 10                  & naive\\_bayes\\_bow & 0.952380952380952   & 0.0113798008534851  & 0.964912280701754   & 0.958605664488017   & 0.9796573875803    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "fold | method | tpr | fpr | prec | f1 | acc | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1                   | naive_bayes_bow     | 0.960869565217391   | 0.00852272727272727 | 0.973568281938326   | 0.967177242888403   | 0.983940042826552   | \n",
       "| 2                   | naive_bayes_bow     | 0.956175298804781   | 0.00878477306002928 | 0.975609756097561   | 0.96579476861167    | 0.981798715203426   | \n",
       "| 3                   | naive_bayes_bow     | 0.960352422907489   | 0.0099009900990099  | 0.968888888888889   | 0.964601769911505   | 0.982869379014989   | \n",
       "| 4                   | naive_bayes_bow     | 0.943127962085308   | 0.00276625172890733 | 0.990049751243781   | 0.966019417475728   | 0.985010706638116   | \n",
       "| 5                   | naive_bayes_bow     | 0.962655601659751   | 0.00577200577200577 | 0.983050847457627   | 0.972746331236897   | 0.986081370449679   | \n",
       "| 6                   | naive_bayes_bow     | 0.975903614457831   | 0.00875912408759124 | 0.975903614457831   | 0.975903614457831   | 0.987152034261242   | \n",
       "| 7                   | naive_bayes_bow     | 0.956               | 0.0087719298245614  | 0.975510204081633   | 0.965656565656566   | 0.981798715203426   | \n",
       "| 8                   | naive_bayes_bow     | 0.936254980079681   | 0.00732064421669107 | 0.979166666666667   | 0.957230142566191   | 0.977516059957173   | \n",
       "| 9                   | naive_bayes_bow     | 0.956862745098039   | 0.00441826215022091 | 0.987854251012146   | 0.97211155378486    | 0.985010706638116   | \n",
       "| 10                  | naive_bayes_bow     | 0.952380952380952   | 0.0113798008534851  | 0.964912280701754   | 0.958605664488017   | 0.9796573875803     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      fold method          tpr               fpr                \n",
       " [1,] 1    naive_bayes_bow 0.960869565217391 0.00852272727272727\n",
       " [2,] 2    naive_bayes_bow 0.956175298804781 0.00878477306002928\n",
       " [3,] 3    naive_bayes_bow 0.960352422907489 0.0099009900990099 \n",
       " [4,] 4    naive_bayes_bow 0.943127962085308 0.00276625172890733\n",
       " [5,] 5    naive_bayes_bow 0.962655601659751 0.00577200577200577\n",
       " [6,] 6    naive_bayes_bow 0.975903614457831 0.00875912408759124\n",
       " [7,] 7    naive_bayes_bow 0.956             0.0087719298245614 \n",
       " [8,] 8    naive_bayes_bow 0.936254980079681 0.00732064421669107\n",
       " [9,] 9    naive_bayes_bow 0.956862745098039 0.00441826215022091\n",
       "[10,] 10   naive_bayes_bow 0.952380952380952 0.0113798008534851 \n",
       "      prec              f1                acc              \n",
       " [1,] 0.973568281938326 0.967177242888403 0.983940042826552\n",
       " [2,] 0.975609756097561 0.96579476861167  0.981798715203426\n",
       " [3,] 0.968888888888889 0.964601769911505 0.982869379014989\n",
       " [4,] 0.990049751243781 0.966019417475728 0.985010706638116\n",
       " [5,] 0.983050847457627 0.972746331236897 0.986081370449679\n",
       " [6,] 0.975903614457831 0.975903614457831 0.987152034261242\n",
       " [7,] 0.975510204081633 0.965656565656566 0.981798715203426\n",
       " [8,] 0.979166666666667 0.957230142566191 0.977516059957173\n",
       " [9,] 0.987854251012146 0.97211155378486  0.985010706638116\n",
       "[10,] 0.964912280701754 0.958605664488017 0.9796573875803  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculate our metrics for naive Bayes\n",
    "cvratesNBbow = cbind(\"fold\" = 1:k,\n",
    "              \"method\" = rep(\"naive_bayes_bow\",k),\n",
    "              \"tpr\" = unlist(lapply(1:k, function(i) truePosRate(testFoldPred[,i], testFoldSpam[,i]))), \n",
    "              \"fpr\" = unlist(lapply(1:k, function(i) falsePosRate(testFoldPred[,i], testFoldSpam[,i]))),\n",
    "              \"prec\" = unlist(lapply(1:k, function(i) precision(testFoldPred[,i], testFoldSpam[,i]))),\n",
    "              \"f1\" = unlist(lapply(1:k, function(i) f1score(testFoldPred[,i], testFoldSpam[,i]))),\n",
    "              \"acc\" = unlist(lapply(1:k, function(i) accuracy(testFoldPred[,i], testFoldSpam[,i]))))\n",
    "cvratesNBbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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",
      "text/plain": [
       "Plot with title \"Receiver Operating Characteristic\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(cvratesNBbow[,4], cvratesNBbow[,3], ylim=c(0,1), xlim=c(0,1), pch=4, col=\"blue\",\n",
    "     xlab=\"False Positive Rate\", ylab=\"True Positive Rate\", main=\"Receiver Operating Characteristic\")\n",
    "abline(0, 1, lty=5, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The other models\n",
    "The preceding work was not just a naive Bayes classifier but a naive Bayes classifier using a bag-of-words framework. While it is not impossible to use the bag-of-words framework for the other models it will require some work to get the data into a usable format using bag-of-words. The following section will instead import the derived dataset as described in Nolan and Lang's text and proceed to use `naive_bayes`, `rpart`, and `random_forest` classifiers from their respective packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 9348   30\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "#this is for the CART part later\n",
    "load(\"spamAssassinDerivedDF.rda\")\n",
    "print(dim(emailDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some setup for naivebayes\n",
    "library(naivebayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some setup for rpart, this is from Nolan and Lang's code\n",
    "library(rpart)\n",
    "\n",
    "setupRpart = function(data) {\n",
    "  logicalVars = which(sapply(data, is.logical))\n",
    "  facVars = lapply(data[ , logicalVars], \n",
    "                   function(x) {\n",
    "                      x = as.factor(x)\n",
    "                      levels(x) = c(\"F\", \"T\")\n",
    "                      x\n",
    "                   })\n",
    "  cbind(facVars, data[ , - logicalVars])\n",
    "}\n",
    "\n",
    "emailDFrp = setupRpart(emailDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some setup for random forest\n",
    "#taken from Professor Slater's notebook\n",
    "#tried using randomForest on emailDF and quickly realized there was something wrong\n",
    "library(randomForest)\n",
    "setupRnum = function(data) {\n",
    "  logicalVars = which(sapply(data, is.logical))\n",
    "  facVars = lapply(data[ , logicalVars], \n",
    "                   function(x) {\n",
    "                      x = as.numeric(x)\n",
    "                   })\n",
    "  cbind(facVars, data[ , - logicalVars])\n",
    "}\n",
    "\n",
    "emailDFnum = setupRnum(emailDF)\n",
    "\n",
    "#convert any na's to 0\n",
    "emailDFnum[is.na(emailDFnum)] <- 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the seed for reproducibility\n",
    "#i'm not using caret, obviously. cv doesn't seem too unmanageable at this time\n",
    "set.seed(418910)\n",
    "\n",
    "#setup our folds, we'll use the same folds for every model we try\n",
    "k = 10 #set k\n",
    "numTrain = dim(emailDF)[1] #get number of training observations\n",
    "partK = sample(numTrain) #randomly sample digits between 1 and numTrain\n",
    "tot = k * floor(numTrain/k) #set the total number of observations we'll use in all k folds, ensures even amounts\n",
    "partK = matrix(partK[1:tot], ncol = k) #matrix using the the first tot items in the vector version of partK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>0.277301927194861</li>\n",
       "\t<li>0.282655246252677</li>\n",
       "\t<li>0.247323340471092</li>\n",
       "\t<li>0.265524625267666</li>\n",
       "\t<li>0.259100642398287</li>\n",
       "\t<li>0.243040685224839</li>\n",
       "\t<li>0.246252676659529</li>\n",
       "\t<li>0.245182012847966</li>\n",
       "\t<li>0.243040685224839</li>\n",
       "\t<li>0.253747323340471</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 0.277301927194861\n",
       "\\item 0.282655246252677\n",
       "\\item 0.247323340471092\n",
       "\\item 0.265524625267666\n",
       "\\item 0.259100642398287\n",
       "\\item 0.243040685224839\n",
       "\\item 0.246252676659529\n",
       "\\item 0.245182012847966\n",
       "\\item 0.243040685224839\n",
       "\\item 0.253747323340471\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 0.277301927194861\n",
       "2. 0.282655246252677\n",
       "3. 0.247323340471092\n",
       "4. 0.265524625267666\n",
       "5. 0.259100642398287\n",
       "6. 0.243040685224839\n",
       "7. 0.246252676659529\n",
       "8. 0.245182012847966\n",
       "9. 0.243040685224839\n",
       "10. 0.253747323340471\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] 0.2773019\n",
       "\n",
       "[[2]]\n",
       "[1] 0.2826552\n",
       "\n",
       "[[3]]\n",
       "[1] 0.2473233\n",
       "\n",
       "[[4]]\n",
       "[1] 0.2655246\n",
       "\n",
       "[[5]]\n",
       "[1] 0.2591006\n",
       "\n",
       "[[6]]\n",
       "[1] 0.2430407\n",
       "\n",
       "[[7]]\n",
       "[1] 0.2462527\n",
       "\n",
       "[[8]]\n",
       "[1] 0.245182\n",
       "\n",
       "[[9]]\n",
       "[1] 0.2430407\n",
       "\n",
       "[[10]]\n",
       "[1] 0.2537473\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking if the proportion of spam in our folds is similar to the actual\n",
    "lapply(1:k, function(i) sum(emailDF[partK[,i],\"isSpam\"])/(dim(partK)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#running cv for naive bayes model from naivebayes package\n",
    "testFoldPredNB = NULL\n",
    "testFoldPredRP = NULL\n",
    "testFoldPredRF = NULL\n",
    "testFoldSpam = NULL\n",
    "for (i in 1:k) {\n",
    "  foldIdx = partK[ , i] #isolate indices for testing\n",
    "  nb <- naive_bayes(isSpam ~ ., data=emailDF[-foldIdx,]) #train with all data except for the test fold \n",
    "  rp <- rpart(isSpam ~ ., data = emailDFrp[-foldIdx,], method = \"class\")\n",
    "  rf <- randomForest(as.factor(isSpam) ~ ., data=emailDFnum[-foldIdx,], ntree=100)\n",
    "  testFoldPredNB = c(testFoldPredNB, as.logical(predict(nb, newdata=emailDF[foldIdx,])))\n",
    "  testFoldPredRP = c(testFoldPredRP, apply(predict(rp, newdata=emailDFrp[foldIdx,]),1, \n",
    "                                           function(x) which.max(x)-1) == 1)\n",
    "  testFoldPredRF = c(testFoldPredRF, (predict(rf, newdata=emailDFnum[foldIdx,]) == 1))\n",
    "  testFoldSpam = c(testFoldSpam, emailDF[foldIdx,'isSpam'])\n",
    "}\n",
    "\n",
    "#expand the odds and actual labels into matrices, one column for each set of out-of-sample folds\n",
    "testFoldPredNB = matrix(testFoldPredNB, ncol=k)\n",
    "testFoldPredRP = matrix(testFoldPredRP, ncol=k)\n",
    "testFoldPredRF = matrix(testFoldPredRF, ncol=k)\n",
    "testFoldSpam = matrix(testFoldSpam, ncol=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can calculate all of our metrics for naivebayes and place it in nice matrix format\n",
    "nbcvrates = cbind(\"fold\" = 1:k,\n",
    "              \"method\" = rep(\"naive_bayes\",k),\n",
    "              \"tpr\" = unlist(lapply(1:k, function(i) truePosRate(testFoldPredNB[,i], testFoldSpam[,i]))), \n",
    "              \"fpr\" = unlist(lapply(1:k, function(i) falsePosRate(testFoldPredNB[,i], testFoldSpam[,i]))),\n",
    "              \"prec\" = unlist(lapply(1:k, function(i) precision(testFoldPredNB[,i], testFoldSpam[,i]))),\n",
    "              \"f1\" = unlist(lapply(1:k, function(i) f1score(testFoldPredNB[,i], testFoldSpam[,i]))),\n",
    "              \"acc\" = unlist(lapply(1:k, function(i) accuracy(testFoldPredNB[,i], testFoldSpam[,i]))))\n",
    "rpcvrates = cbind(\"fold\" = 1:k,\n",
    "              \"method\" = rep(\"rpart\",k),\n",
    "              \"tpr\" = unlist(lapply(1:k, function(i) truePosRate(testFoldPredRP[,i], testFoldSpam[,i]))), \n",
    "              \"fpr\" = unlist(lapply(1:k, function(i) falsePosRate(testFoldPredRP[,i], testFoldSpam[,i]))),\n",
    "              \"prec\" = unlist(lapply(1:k, function(i) precision(testFoldPredRP[,i], testFoldSpam[,i]))),\n",
    "              \"f1\" = unlist(lapply(1:k, function(i) f1score(testFoldPredRP[,i], testFoldSpam[,i]))),\n",
    "              \"acc\" = unlist(lapply(1:k, function(i) accuracy(testFoldPredRP[,i], testFoldSpam[,i]))))\n",
    "rfcvrates = cbind(\"fold\" = 1:k,\n",
    "              \"method\" = rep(\"randomForest\",k),\n",
    "              \"tpr\" = unlist(lapply(1:k, function(i) truePosRate(testFoldPredRF[,i], testFoldSpam[,i]))), \n",
    "              \"fpr\" = unlist(lapply(1:k, function(i) falsePosRate(testFoldPredRF[,i], testFoldSpam[,i]))),\n",
    "              \"prec\" = unlist(lapply(1:k, function(i) precision(testFoldPredRF[,i], testFoldSpam[,i]))),\n",
    "              \"f1\" = unlist(lapply(1:k, function(i) f1score(testFoldPredRF[,i], testFoldSpam[,i]))),\n",
    "              \"acc\" = unlist(lapply(1:k, function(i) accuracy(testFoldPredRF[,i], testFoldSpam[,i]))))\n",
    "cvrates = rbind(cvratesNBbow, nbcvrates, rpcvrates, rfcvrates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will put \"method\" as the first column\n",
    "cvrates = as.matrix(merge(cvrates, cbind(\"method\"=unique(cvrates[,2]),\"num_method\"=c(1,2,3,4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAAP8AzQBNTU1o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\nIA6q6iAAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Receiver Operating Characteristic\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(cvrates[,4], cvrates[,3], ylim=c(0,1), xlim=c(0,1), pch=as.integer(cvrates[,8]), col=cvrates[,8],\n",
    "     xlab=\"False Positive Rate\", ylab=\"True Positive Rate\", main=\"Receiver Operating Characteristic\")\n",
    "abline(0, 1, lty=5, col=\"red\")\n",
    "legend(0.7, 0.2, legend=unique(cvrates[,1]),\n",
    "       col=as.integer(unique(cvrates[,8])), pch=as.integer(unique(cvrates[,8])), cex=0.8)\n",
    "# plot(cvrates[,4], cvrates[,3], pch=as.integer(cvrates[,8]), col=cvrates[,8],\n",
    "#      xlab=\"False Positive Rate\", ylab=\"True Positive Rate\", main=\"Receiver Operating Characteristic\")\n",
    "# legend(0.05, 0.97, legend=unique(cvrates[,1]),\n",
    "#        col=as.integer(unique(cvrates[,8])), pch=as.integer(unique(cvrates[,8])), cex=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using naive Bayes outside of the bag-of-words framework is not so great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
